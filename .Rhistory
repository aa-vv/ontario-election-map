result.candidate <- model.test(model.candidate, 2, T, data.build, index.test)[[2]]
print(result.candidate)
model.test <- function(model.name, runs, preprocessing, data.build, index.test) {
models <- list()
result <- data.frame(matrix(NA, nrow = runs, ncol = length(model.name)))
names(result) <- model.name
for (j in 1:length(model.name)) {
model.selected <- model.name[j]
l <- foreach (i = 1:runs) %dopar% {
train <- data.build[-index.test[[i]],]
test <- data.build[index.test[[i]],]
# preprocessing
if (preprocessing) {
pca.train <- preProcess(train[,-dim(data.build)[2]], method = "pca", thresh = 0.80)
feature.train <- predict(pca.train, train[,-dim(data.build)[2]])
feature.test <- predict(pca.train, test[,-dim(data.build)[2]])
feature.train$classe <- train$classe
feature.test$classe <- test$classe
train <- feature.train
test <- feature.test
}
# modeling
if (model.selected == "svm") {
model <- svm(classe ~ ., data = train)
} else if (model.selected == "multinom") {
model <- multinom(classe ~ ., data = train)
} else {
model <- train(classe ~ ., method = model.selected, data = train)
}
prediction <- predict(model, test)
result <- confusionMatrix(prediction, test$classe)$overall[1]
return(list(model, result))
}
print(l)
# model[[j]] <- sapply(l, "[[", 1)
models[[j]] <- l[[1]][[1]]
# print(models[[j]])
print(sapply(l, "[", 1))
result[,j] <- unlist(sapply(l, "[[", 2))
}
return(list(models, result))
}
registerDoParallel(cores = 4)
# 1
# model.candidate <- c("lda", "multinom", "svm", "rpart", "nb", "knn", "rf", "gbm")
model.candidate <- c("lda", "rpart")
result.candidate <- model.test(model.candidate, 2, T, data.build, index.test)[[2]]
print(result.candidate)
library(caret)
library(dplyr)
library(e1071)
library(nnet)
library(tabplot)
library(doParallel)
# set.seed(666)
raw.pack <- read.csv("pml-training.csv")
raw.case <- read.csv("pml-testing.csv")
data.pack <- raw.pack
data.case <- raw.case
na.ratio <- function(data) {
ratio <- vector()
for (i in 1:dim(data)[2]) {
ratio <- c(ratio, sum(is.na(data[,i])) / dim(data)[1])
}
ratio
}
clean <- function(parent, child, match=NULL, na.rm=TRUE) {
for (i in 1:dim(parent)[2]) {
if ((!is.null(match) && !(names(parent)[i] %in% names(match)))
|| (sum(is.na(parent[,i])) > 0.8 * dim(parent[2]))) {
child <- select(child, -c(names(parent)[i]))
}
}
child
}
na.ratio(data.pack); na.ratio(data.case)
data.case <- clean(raw.case, data.case)
data.pack <- clean(raw.pack, data.pack, match=data.case)
dim(data.pack); dim(data.case)
na.ratio(data.pack); na.ratio(data.case)
# explerimental plot
# tableplot(data.pack)
# feature selection
# remove highly correlated variables
data.pack <- data.pack[,sapply(data.pack, is.numeric)][,-c(1,2,3,4)]
data.pack <- data.pack[, -findCorrelation(cor(data.pack), 0.8)]
data.pack$classe <- raw.pack$classe
# rfe.lda <- rfe(data.pack[-40], data.pack[,40],
#                sizes = c(5, 10, 20),
#                rfeControl = rfeControl(functions = caretFuncs, method = "cv", number = 10),
#                method = "lda")
#
# rfe.rpart <- rfe(data.pack[-40], data.pack[,40],
#                sizes = c(5, 10, 20),
#                rfeControl = rfeControl(functions = caretFuncs, method = "cv", number = 10),
#                method = "rpart")
#
# predictors(rfe.lda)
# plot(rfe.lda, type = c("g", "o"))
# plot(rfe.rpart, type = c("g", "o"))
# data slicing
index.validate <- createDataPartition(data.pack$classe, times = 1, p = 0.2, list = F)
data.validate <- data.pack[index.validate,]
data.build <- data.pack[-index.validate,]
fold <- 10
index.test <- createFolds(data.build$classe, k = fold)
# modeling
model.test <- function(model.name, runs, preprocessing, data.build, index.test) {
models <- list()
result <- data.frame(matrix(NA, nrow = runs, ncol = length(model.name)))
names(result) <- model.name
for (j in 1:length(model.name)) {
model.selected <- model.name[j]
l <- foreach (i = 1:runs) %dopar% {
train <- data.build[-index.test[[i]],]
test <- data.build[index.test[[i]],]
# preprocessing
if (preprocessing) {
pca.train <- preProcess(train[,-dim(data.build)[2]], method = "pca", thresh = 0.80)
feature.train <- predict(pca.train, train[,-dim(data.build)[2]])
feature.test <- predict(pca.train, test[,-dim(data.build)[2]])
feature.train$classe <- train$classe
feature.test$classe <- test$classe
train <- feature.train
test <- feature.test
}
# modeling
if (model.selected == "svm") {
model <- svm(classe ~ ., data = train)
} else if (model.selected == "multinom") {
model <- multinom(classe ~ ., data = train)
} else {
model <- train(classe ~ ., method = model.selected, data = train)
}
prediction <- predict(model, test)
result <- confusionMatrix(prediction, test$classe)$overall[1]
return(list(model, result))
}
print(l)
model[[j]] <- sapply(l, "[", 1)
result[,j] <- unlist(sapply(l, "[", 2))
}
return(list(models, result))
}
# test
# registerDoParallel(cores = 4)
#
# model.final <- c("lda", "rpart", "svm")
# rs <- model.test(model.final, 2, F, data.build, index.test)
# model <- rs[[1]]
# result.final <- rs[[2]]
# print(result.final)
registerDoParallel(cores = 4)
# 1
# model.candidate <- c("lda", "multinom", "svm", "rpart", "nb", "knn", "rf", "gbm")
model.candidate <- c("lda", "rpart")
rs <- model.test(model.candidate, 2, T, data.build, index.test)
library(caret)
library(dplyr)
library(e1071)
library(nnet)
library(tabplot)
library(doParallel)
# set.seed(666)
raw.pack <- read.csv("pml-training.csv")
raw.case <- read.csv("pml-testing.csv")
data.pack <- raw.pack
data.case <- raw.case
na.ratio <- function(data) {
ratio <- vector()
for (i in 1:dim(data)[2]) {
ratio <- c(ratio, sum(is.na(data[,i])) / dim(data)[1])
}
ratio
}
clean <- function(parent, child, match=NULL, na.rm=TRUE) {
for (i in 1:dim(parent)[2]) {
if ((!is.null(match) && !(names(parent)[i] %in% names(match)))
|| (sum(is.na(parent[,i])) > 0.8 * dim(parent[2]))) {
child <- select(child, -c(names(parent)[i]))
}
}
child
}
na.ratio(data.pack); na.ratio(data.case)
data.case <- clean(raw.case, data.case)
data.pack <- clean(raw.pack, data.pack, match=data.case)
dim(data.pack); dim(data.case)
na.ratio(data.pack); na.ratio(data.case)
# explerimental plot
# tableplot(data.pack)
# feature selection
# remove highly correlated variables
data.pack <- data.pack[,sapply(data.pack, is.numeric)][,-c(1,2,3,4)]
data.pack <- data.pack[, -findCorrelation(cor(data.pack), 0.8)]
data.pack$classe <- raw.pack$classe
# rfe.lda <- rfe(data.pack[-40], data.pack[,40],
#                sizes = c(5, 10, 20),
#                rfeControl = rfeControl(functions = caretFuncs, method = "cv", number = 10),
#                method = "lda")
#
# rfe.rpart <- rfe(data.pack[-40], data.pack[,40],
#                sizes = c(5, 10, 20),
#                rfeControl = rfeControl(functions = caretFuncs, method = "cv", number = 10),
#                method = "rpart")
#
# predictors(rfe.lda)
# plot(rfe.lda, type = c("g", "o"))
# plot(rfe.rpart, type = c("g", "o"))
# data slicing
index.validate <- createDataPartition(data.pack$classe, times = 1, p = 0.2, list = F)
data.validate <- data.pack[index.validate,]
data.build <- data.pack[-index.validate,]
fold <- 10
index.test <- createFolds(data.build$classe, k = fold)
# modeling
model.test <- function(model.name, runs, preprocessing, data.build, index.test) {
models <- list()
result <- data.frame(matrix(NA, nrow = runs, ncol = length(model.name)))
names(result) <- model.name
for (j in 1:length(model.name)) {
model.selected <- model.name[j]
l <- foreach (i = 1:runs) %dopar% {
train <- data.build[-index.test[[i]],]
test <- data.build[index.test[[i]],]
# preprocessing
if (preprocessing) {
pca.train <- preProcess(train[,-dim(data.build)[2]], method = "pca", thresh = 0.80)
feature.train <- predict(pca.train, train[,-dim(data.build)[2]])
feature.test <- predict(pca.train, test[,-dim(data.build)[2]])
feature.train$classe <- train$classe
feature.test$classe <- test$classe
train <- feature.train
test <- feature.test
}
# modeling
if (model.selected == "svm") {
model <- svm(classe ~ ., data = train)
} else if (model.selected == "multinom") {
model <- multinom(classe ~ ., data = train)
} else {
model <- train(classe ~ ., method = model.selected, data = train)
}
prediction <- predict(model, test)
result <- confusionMatrix(prediction, test$classe)$overall[1]
return(list(model, result))
}
models[[j]] <- sapply(l, "[", 1)
result[,j] <- unlist(sapply(l, "[", 2))
}
return(list(models, result))
}
registerDoParallel(cores = 4)
# 1
# model.candidate <- c("lda", "multinom", "svm", "rpart", "nb", "knn", "rf", "gbm")
model.candidate <- c("lda", "rpart")
rs <- model.test(model.candidate, 2, T, data.build, index.test)
rs
rs[[1]]
rs[[1]][[1]]
rs[[1]][[1]][[1]]
rs[[2]]
library(caret)
library(dplyr)
library(e1071)
library(nnet)
library(tabplot)
library(doParallel)
# set.seed(666)
raw.pack <- read.csv("pml-training.csv")
raw.case <- read.csv("pml-testing.csv")
data.pack <- raw.pack
data.case <- raw.case
na.ratio <- function(data) {
ratio <- vector()
for (i in 1:dim(data)[2]) {
ratio <- c(ratio, sum(is.na(data[,i])) / dim(data)[1])
}
ratio
}
clean <- function(parent, child, match=NULL, na.rm=TRUE) {
for (i in 1:dim(parent)[2]) {
if ((!is.null(match) && !(names(parent)[i] %in% names(match)))
|| (sum(is.na(parent[,i])) > 0.8 * dim(parent[2]))) {
child <- select(child, -c(names(parent)[i]))
}
}
child
}
na.ratio(data.pack); na.ratio(data.case)
data.case <- clean(raw.case, data.case)
data.pack <- clean(raw.pack, data.pack, match=data.case)
dim(data.pack); dim(data.case)
na.ratio(data.pack); na.ratio(data.case)
# explerimental plot
# tableplot(data.pack)
# feature selection
# remove highly correlated variables
data.pack <- data.pack[,sapply(data.pack, is.numeric)][,-c(1,2,3,4)]
data.pack <- data.pack[, -findCorrelation(cor(data.pack), 0.8)]
data.pack$classe <- raw.pack$classe
# rfe.lda <- rfe(data.pack[-40], data.pack[,40],
#                sizes = c(5, 10, 20),
#                rfeControl = rfeControl(functions = caretFuncs, method = "cv", number = 10),
#                method = "lda")
#
# rfe.rpart <- rfe(data.pack[-40], data.pack[,40],
#                sizes = c(5, 10, 20),
#                rfeControl = rfeControl(functions = caretFuncs, method = "cv", number = 10),
#                method = "rpart")
#
# predictors(rfe.lda)
# plot(rfe.lda, type = c("g", "o"))
# plot(rfe.rpart, type = c("g", "o"))
# data slicing
index.validate <- createDataPartition(data.pack$classe, times = 1, p = 0.2, list = F)
data.validate <- data.pack[index.validate,]
data.build <- data.pack[-index.validate,]
fold <- 10
index.test <- createFolds(data.build$classe, k = fold)
# modeling
model.test <- function(model.name, runs, preprocessing, data.build, index.test) {
models <- list()
result <- data.frame(matrix(NA, nrow = runs, ncol = length(model.name)))
names(result) <- model.name
for (j in 1:length(model.name)) {
model.selected <- model.name[j]
l <- foreach (i = 1:runs) %dopar% {
train <- data.build[-index.test[[i]],]
test <- data.build[index.test[[i]],]
# preprocessing
if (preprocessing) {
pca.train <- preProcess(train[,-dim(data.build)[2]], method = "pca", thresh = 0.80)
feature.train <- predict(pca.train, train[,-dim(data.build)[2]])
feature.test <- predict(pca.train, test[,-dim(data.build)[2]])
feature.train$classe <- train$classe
feature.test$classe <- test$classe
train <- feature.train
test <- feature.test
}
# modeling
if (model.selected == "svm") {
model <- svm(classe ~ ., data = train)
} else if (model.selected == "multinom") {
model <- multinom(classe ~ ., data = train)
} else {
model <- train(classe ~ ., method = model.selected, data = train)
}
prediction <- predict(model, test)
result <- confusionMatrix(prediction, test$classe)$overall[1]
return(list(model, result))
}
models[[j]] <- sapply(l, "[", 1)
result[,j] <- unlist(sapply(l, "[", 2))
}
return(list(models, result))
}
# test
# registerDoParallel(cores = 4)
#
# model.final <- c("lda", "rpart", "svm")
# rs <- model.test(model.final, 2, F, data.build, index.test)
# model <- rs[[1]]
# result.final <- rs[[2]]
# print(result.final)
registerDoParallel(cores = 4)
# 1
# model.candidate <- c("lda", "multinom", "svm", "rpart", "nb", "knn", "rf", "gbm")
model.candidate <- c("lda", "rpart")
result.candidate <- model.test(model.candidate, 2, T, data.build, index.test)[[2]]
print(result.candidate)
model.top <- model.candidate[order(result.candidate, decreasing = T)[1:2]]
result.top <- model.test(model.top, 1, F, data.build, index.test)[[2]]
print(result.top)
model.final <- model.top[order(result.top, decreasing = T)[1]]
l <- model.test(model.final, 10, F, data.build, index.test)
model <- l[[1]]
result.final <- l[[2]]
print(result.final)
model
model[[1]]
# validation
prediction.validate <- predict(model[[1]][[order(result.final, decreasing = T)[1]]], data.validate)
result.validate <- confusionMatrix(prediction.validate, data.validate$classe)$overall[1]
print(result.validate)
prediction.case <- predict(model[[1]][[order(result.final, decreasing = T)[1]]], data.case)
print(prediction.case)
library(caret)
library(dplyr)
library(e1071)
library(nnet)
library(tabplot)
library(doParallel)
# set.seed(666)
raw.pack <- read.csv("pml-training.csv")
raw.case <- read.csv("pml-testing.csv")
data.pack <- raw.pack
data.case <- raw.case
na.ratio <- function(data) {
ratio <- vector()
for (i in 1:dim(data)[2]) {
ratio <- c(ratio, sum(is.na(data[,i])) / dim(data)[1])
}
ratio
}
clean <- function(parent, child, match=NULL, na.rm=TRUE) {
for (i in 1:dim(parent)[2]) {
if ((!is.null(match) && !(names(parent)[i] %in% names(match)))
|| (sum(is.na(parent[,i])) > 0.8 * dim(parent[2]))) {
child <- select(child, -c(names(parent)[i]))
}
}
child
}
na.ratio(data.pack); na.ratio(data.case)
data.case <- clean(raw.case, data.case)
data.pack <- clean(raw.pack, data.pack, match=data.case)
dim(data.pack); dim(data.case)
na.ratio(data.pack); na.ratio(data.case)
# explerimental plot
# tableplot(data.pack)
# feature selection
# remove highly correlated variables
data.pack <- data.pack[,sapply(data.pack, is.numeric)][,-c(1,2,3,4)]
data.pack <- data.pack[, -findCorrelation(cor(data.pack), 0.8)]
data.pack$classe <- raw.pack$classe
# rfe.lda <- rfe(data.pack[-40], data.pack[,40],
#                sizes = c(5, 10, 20),
#                rfeControl = rfeControl(functions = caretFuncs, method = "cv", number = 10),
#                method = "lda")
#
# rfe.rpart <- rfe(data.pack[-40], data.pack[,40],
#                sizes = c(5, 10, 20),
#                rfeControl = rfeControl(functions = caretFuncs, method = "cv", number = 10),
#                method = "rpart")
#
# predictors(rfe.lda)
# plot(rfe.lda, type = c("g", "o"))
# plot(rfe.rpart, type = c("g", "o"))
# data slicing
index.validate <- createDataPartition(data.pack$classe, times = 1, p = 0.2, list = F)
data.validate <- data.pack[index.validate,]
data.build <- data.pack[-index.validate,]
fold <- 10
index.test <- createFolds(data.build$classe, k = fold)
# modeling
model.test <- function(model.name, runs, preprocessing, data.build, index.test) {
models <- list()
results <- data.frame(matrix(NA, nrow = runs, ncol = length(model.name)))
names(results) <- model.name
for (j in 1:length(model.name)) {
model.selected <- model.name[j]
l <- foreach (i = 1:runs) %dopar% {
train <- data.build[-index.test[[i]],]
test <- data.build[index.test[[i]],]
# preprocessing
if (preprocessing) {
pca.train <- preProcess(train[,-dim(data.build)[2]], method = "pca", thresh = 0.80)
feature.train <- predict(pca.train, train[,-dim(data.build)[2]])
feature.test <- predict(pca.train, test[,-dim(data.build)[2]])
feature.train$classe <- train$classe
feature.test$classe <- test$classe
train <- feature.train
test <- feature.test
}
# modeling
if (model.selected == "svm") {
model <- svm(classe ~ ., data = train)
} else if (model.selected == "multinom") {
model <- multinom(classe ~ ., data = train)
} else {
model <- train(classe ~ ., method = model.selected, data = train)
}
prediction <- predict(model, test)
result <- confusionMatrix(prediction, test$classe)$overall[1]
return(list(model, result))
}
models[[j]] <- sapply(l, "[", 1)
results[,j] <- unlist(sapply(l, "[", 2))
}
return(list(models, results))
}
registerDoParallel(cores = 4)
# 1
# model.candidate <- c("lda", "multinom", "svm", "rpart", "nb", "knn", "rf", "gbm")
model.candidate <- c("lda", "rpart")
result.candidate <- model.test(model.candidate, 1, T, data.build, index.test)[[2]]
print(result.candidate)
setwd("~/ws/ontario-election-2018")
install.packages("rgdal")
install.packages("leaflet")
install.packages("maptools")
install.packages("gpclib")
install.packages("rgeos")
install.packages("rgeos")
install.packages("rgeos")
r
r
install.packages("rgeos")
install.packages("rgdal")
install.packages("rgdal")
install.packages("rgeos")
install.packages("rgdal")
install.packages("rgdal")
install.packages("rgdal")
install.packages("rgdal")
install.packages("rgdal")
install.packages("rgdal")
install.packages("rgdal")
install.packages("rgdal")
install.packages("rgdal")
install.packages("rgdal")
